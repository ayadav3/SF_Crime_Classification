{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from copy import deepcopy\n",
    "# %matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF=pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n",
      "abc\n",
      "abc\n",
      "abc\n"
     ]
    }
   ],
   "source": [
    "xy_scaler=preprocessing.StandardScaler()\n",
    "print \"abc\"\n",
    "xy_scaler.fit(trainDF[[\"X\",\"Y\"]])\n",
    "print \"abc\"\n",
    "trainDF[[\"X\",\"Y\"]]=xy_scaler.transform(trainDF[[\"X\",\"Y\"]])\n",
    "print \"abc\"\n",
    "trainDF=trainDF[abs(trainDF[\"Y\"])<100]\n",
    "print \"abc\"\n",
    "trainDF.index=range(len(trainDF))\n",
    "# plt.plot(trainDF[\"X\"],trainDF[\"Y\"],'.')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NX=100\n",
    "NY=100\n",
    "groups = trainDF.groupby('Category')\n",
    "ii=1\n",
    "plt.figure(figsize=(20, 20))\n",
    "for name, group in groups:\n",
    "    plt.subplot(8,5,ii)\n",
    "    histo, xedges, yedges = np.histogram2d(np.array(group.X),np.array(group.Y), bins=(NX,NY))\n",
    "    myextent  =[xedges[0],xedges[-1],yedges[0],yedges[-1]]\n",
    "    plt.imshow(histo.T,origin='low',extent=myextent,interpolation='nearest',aspect='auto',norm=LogNorm())\n",
    "    plt.title(name)\n",
    "#     plt.figure(ii)\n",
    "#     plt.plot(group.X,group.Y,'.')\n",
    "    ii+=1\n",
    "del groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")\n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    return time,day,month,year\n",
    "\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_data(df,logodds,logoddsPA):\n",
    "    feature_list=df.columns.tolist()\n",
    "    if \"Descript\" in feature_list:\n",
    "        feature_list.remove(\"Descript\")\n",
    "    if \"Resolution\" in feature_list:\n",
    "        feature_list.remove(\"Resolution\")\n",
    "    if \"Category\" in feature_list:\n",
    "        feature_list.remove(\"Category\")\n",
    "    if \"Id\" in feature_list:\n",
    "        feature_list.remove(\"Id\")\n",
    "    cleanData=df[feature_list]\n",
    "    cleanData.index=range(len(df))\n",
    "    print \"Creating address features\"\n",
    "    address_features=cleanData[\"Address\"].apply(lambda x: logodds[x])\n",
    "    address_features.columns=[\"logodds\"+str(x) for x in range(len(address_features.columns))]\n",
    "    print \"Parsing dates\"\n",
    "    cleanData[\"Time\"], cleanData[\"Day\"], cleanData[\"Month\"], cleanData[\"Year\"]=zip(*cleanData[\"Dates\"].apply(parse_time))\n",
    "#     dummy_ranks_DAY = pd.get_dummies(cleanData['DayOfWeek'], prefix='DAY')\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "#     cleanData[\"DayOfWeek\"]=cleanData[\"DayOfWeek\"].apply(lambda x: days.index(x)/float(len(days)))\n",
    "    print \"Creating one-hot variables\"\n",
    "    dummy_ranks_PD = pd.get_dummies(cleanData['PdDistrict'], prefix='PD')\n",
    "    dummy_ranks_DAY = pd.get_dummies(cleanData[\"DayOfWeek\"], prefix='DAY')\n",
    "    cleanData[\"IsInterection\"]=cleanData[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    cleanData[\"logoddsPA\"]=cleanData[\"Address\"].apply(lambda x: logoddsPA[x])\n",
    "    print \"droping processed columns\"\n",
    "    cleanData=cleanData.drop(\"PdDistrict\",axis=1)\n",
    "    cleanData=cleanData.drop(\"DayOfWeek\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Address\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Dates\",axis=1)\n",
    "    feature_list=cleanData.columns.tolist()\n",
    "    print \"joining one-hot features\"\n",
    "    features = cleanData[feature_list].join(dummy_ranks_PD.ix[:,:]).join(dummy_ranks_DAY.ix[:,:]).join(address_features.ix[:,:])\n",
    "    print \"creating new features\"\n",
    "    features[\"IsDup\"]=pd.Series(features.duplicated()|features.duplicated(take_last=True)).apply(int)\n",
    "    features[\"Awake\"]=features[\"Time\"].apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "    features[\"Summer\"], features[\"Fall\"], features[\"Winter\"], features[\"Spring\"]=zip(*features[\"Month\"].apply(get_season))\n",
    "    if \"Category\" in df.columns:\n",
    "        print df[\"Category\"]\n",
    "        labels = df[\"Category\"].astype('category')\n",
    "        #labels = df[\"Category\"].unique()\n",
    "#         label_names=labels.unique()\n",
    "#         labels=labels.cat.rename_categories(range(len(label_names)))\n",
    "    else:\n",
    "        labels=None\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addresses=sorted(trainDF[\"Address\"].unique())\n",
    "categories=sorted(trainDF[\"Category\"].unique())\n",
    "C_counts=trainDF.groupby([\"Category\"]).size()\n",
    "A_C_counts=trainDF.groupby([\"Address\",\"Category\"]).size()\n",
    "A_counts=trainDF.groupby([\"Address\"]).size()\n",
    "logodds={}\n",
    "logoddsPA={}\n",
    "MIN_CAT_COUNTS=2\n",
    "default_logodds=np.log(C_counts/len(trainDF))-np.log(1.0-C_counts/float(len(trainDF)))\n",
    "for addr in addresses:\n",
    "    PA=A_counts[addr]/float(len(trainDF))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "    logodds[addr]=deepcopy(default_logodds)\n",
    "    for cat in A_C_counts[addr].keys():\n",
    "        if (A_C_counts[addr][cat]>MIN_CAT_COUNTS) and A_C_counts[addr][cat]<A_counts[addr]:\n",
    "            PA=A_C_counts[addr][cat]/float(A_counts[addr])\n",
    "            logodds[addr][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "    logodds[addr]=pd.Series(logodds[addr])\n",
    "    logodds[addr].index=range(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating address features\n",
      "Parsing dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating one-hot variables\n",
      "droping processed columns\n",
      "joining one-hot features\n",
      "creating new features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:35: FutureWarning: the take_last=True keyword is deprecated, use keep='last' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       WARRANTS\n",
      "1                 OTHER OFFENSES\n",
      "2                 OTHER OFFENSES\n",
      "3                  LARCENY/THEFT\n",
      "4                  LARCENY/THEFT\n",
      "5                  LARCENY/THEFT\n",
      "6                  VEHICLE THEFT\n",
      "7                  VEHICLE THEFT\n",
      "8                  LARCENY/THEFT\n",
      "9                  LARCENY/THEFT\n",
      "10                 LARCENY/THEFT\n",
      "11                OTHER OFFENSES\n",
      "12                     VANDALISM\n",
      "13                 LARCENY/THEFT\n",
      "14                  NON-CRIMINAL\n",
      "15                  NON-CRIMINAL\n",
      "16                       ROBBERY\n",
      "17                       ASSAULT\n",
      "18                OTHER OFFENSES\n",
      "19                  NON-CRIMINAL\n",
      "20                 LARCENY/THEFT\n",
      "21                       ROBBERY\n",
      "22                      WARRANTS\n",
      "23                  NON-CRIMINAL\n",
      "24                 LARCENY/THEFT\n",
      "25                  NON-CRIMINAL\n",
      "26                 LARCENY/THEFT\n",
      "27                 LARCENY/THEFT\n",
      "28                 LARCENY/THEFT\n",
      "29                OTHER OFFENSES\n",
      "                   ...          \n",
      "877952            OTHER OFFENSES\n",
      "877953            OTHER OFFENSES\n",
      "877954                 VANDALISM\n",
      "877955             VEHICLE THEFT\n",
      "877956             LARCENY/THEFT\n",
      "877957            OTHER OFFENSES\n",
      "877958            OTHER OFFENSES\n",
      "877959                  WARRANTS\n",
      "877960                  WARRANTS\n",
      "877961                   ASSAULT\n",
      "877962            OTHER OFFENSES\n",
      "877963     SEX OFFENSES FORCIBLE\n",
      "877964                   ASSAULT\n",
      "877965            OTHER OFFENSES\n",
      "877966                 VANDALISM\n",
      "877967                  TRESPASS\n",
      "877968                   ASSAULT\n",
      "877969             LARCENY/THEFT\n",
      "877970                 VANDALISM\n",
      "877971                  WARRANTS\n",
      "877972            OTHER OFFENSES\n",
      "877973                   ASSAULT\n",
      "877974            OTHER OFFENSES\n",
      "877975                   ASSAULT\n",
      "877976            OTHER OFFENSES\n",
      "877977                   ROBBERY\n",
      "877978             LARCENY/THEFT\n",
      "877979             LARCENY/THEFT\n",
      "877980                 VANDALISM\n",
      "877981    FORGERY/COUNTERFEITING\n",
      "Name: Category, dtype: object\n"
     ]
    }
   ],
   "source": [
    "features, labels=parse_data(trainDF,logodds,logoddsPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Time', 'Day', 'Month', 'Year', 'IsInterection', 'logoddsPA', 'PD_BAYVIEW', 'PD_CENTRAL', 'PD_INGLESIDE', 'PD_MISSION', 'PD_NORTHERN', 'PD_PARK', 'PD_RICHMOND', 'PD_SOUTHERN', 'PD_TARAVAL', 'PD_TENDERLOIN', 'DAY_Friday', 'DAY_Monday', 'DAY_Saturday', 'DAY_Sunday', 'DAY_Thursday', 'DAY_Tuesday', 'DAY_Wednesday', 'logodds0', 'logodds1', 'logodds2', 'logodds3', 'logodds4', 'logodds5', 'logodds6', 'logodds7', 'logodds8', 'logodds9', 'logodds10', 'logodds11', 'logodds12', 'logodds13', 'logodds14', 'logodds15', 'logodds16', 'logodds17', 'logodds18', 'logodds19', 'logodds20', 'logodds21', 'logodds22', 'logodds23', 'logodds24', 'logodds25', 'logodds26', 'logodds27', 'logodds28', 'logodds29', 'logodds30', 'logodds31', 'logodds32', 'logodds33', 'logodds34', 'logodds35', 'logodds36', 'logodds37', 'logodds38', 'IsDup', 'Awake', 'Summer', 'Fall', 'Winter', 'Spring']\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print features.columns.tolist()\n",
    "print len(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# num_feature_list=[\"Time\",\"Day\",\"Month\",\"Year\",\"DayOfWeek\"]\n",
    "collist=features.columns.tolist()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[collist]=scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X         Y      Time       Day     Month      Year  IsInterection  \\\n",
      "1 -0.123732  0.313018  1.463812 -0.292669 -0.418903  1.731591       1.538547   \n",
      "2 -0.063274  1.381346  1.463812 -0.292669 -0.418903  1.731591       1.538547   \n",
      "3 -0.167381  1.400312  1.463812 -0.292669 -0.418903  1.731591      -0.649964   \n",
      "4 -0.631787  0.186493  1.463812 -0.292669 -0.418903  1.731591      -0.649964   \n",
      "5  0.771649 -2.218282  1.463812 -0.292669 -0.418903  1.731591      -0.649964   \n",
      "6 -0.022298 -1.733799  1.463812 -0.292669 -0.418903  1.731591       1.538547   \n",
      "7  2.036376 -1.633403  1.463812 -0.292669 -0.418903  1.731591       1.538547   \n",
      "8 -3.378776  0.395894  1.463812 -0.292669 -0.418903  1.731591      -0.649964   \n",
      "9  0.145365  1.687050  1.463812 -0.292669 -0.418903  1.731591       1.538547   \n",
      "\n",
      "   logoddsPA  PD_BAYVIEW  PD_CENTRAL    ...     logodds35  logodds36  \\\n",
      "1  -0.645441   -0.336748   -0.328369    ...      0.172386   0.668083   \n",
      "2  -1.009236   -0.336748   -0.328369    ...      0.172386   0.331867   \n",
      "3   0.024967   -0.336748   -0.328369    ...     -0.222705  -0.229219   \n",
      "4  -0.567072   -0.336748   -0.328369    ...      1.113007   0.740414   \n",
      "5  -0.421660   -0.336748   -0.328369    ...      0.710170   1.143856   \n",
      "6  -2.708725   -0.336748   -0.328369    ...      0.172386   0.331867   \n",
      "7  -1.957335    2.969581   -0.328369    ...      0.172386   0.331867   \n",
      "8  -1.058545   -0.336748   -0.328369    ...      1.730282   1.403657   \n",
      "9  -0.865217   -0.336748    3.045358    ...      0.172386   0.331867   \n",
      "\n",
      "   logodds37  logodds38     IsDup     Awake   Summer      Fall    Winter  \\\n",
      "1   0.415560  -0.194372  1.257823  0.390475  1.72683 -0.579573 -0.447534   \n",
      "2  -0.242038  -0.194372 -0.795025  0.390475  1.72683 -0.579573 -0.447534   \n",
      "3  -2.023754  -0.194372 -0.795025  0.390475  1.72683 -0.579573 -0.447534   \n",
      "4  -0.242038  -0.194372 -0.795025  0.390475  1.72683 -0.579573 -0.447534   \n",
      "5  -0.242038  -0.194372 -0.795025  0.390475  1.72683 -0.579573 -0.447534   \n",
      "6  -0.242038  -0.194372 -0.795025  0.390475  1.72683 -0.579573 -0.447534   \n",
      "7  -0.242038  -0.194372 -0.795025  0.390475  1.72683 -0.579573 -0.447534   \n",
      "8  -0.242038  -0.194372 -0.795025  0.390475  1.72683 -0.579573 -0.447534   \n",
      "9   1.253502  -0.194372 -0.795025  0.390475  1.72683 -0.579573 -0.447534   \n",
      "\n",
      "     Spring  \n",
      "1 -0.587391  \n",
      "2 -0.587391  \n",
      "3 -0.587391  \n",
      "4 -0.587391  \n",
      "5 -0.587391  \n",
      "6 -0.587391  \n",
      "7 -0.587391  \n",
      "8 -0.587391  \n",
      "9 -0.587391  \n",
      "\n",
      "[9 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "print features[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07714363  0.06267647  0.04861061  0.04300871  0.03340587  0.03085896\n",
      "  0.02834616  0.02731142  0.02509795  0.02393235  0.02272111  0.02029053\n",
      "  0.02000664  0.019452    0.01918369  0.01820193  0.01729548  0.01724542\n",
      "  0.01715838  0.01714426  0.01703779  0.01695665  0.01668107  0.01651773\n",
      "  0.01626539  0.01588035  0.01489293  0.01472615  0.01422875  0.01412131\n",
      "  0.0136947   0.01330571  0.01234474  0.01181851  0.01158515  0.01126484\n",
      "  0.01104143  0.0105683   0.01032344  0.00943963  0.00903894  0.00838257\n",
      "  0.00819149  0.00795652  0.0074206   0.00726109  0.00707183  0.00675531\n",
      "  0.0067189   0.00646287  0.00634686  0.00612685  0.0060737   0.00556134\n",
      "  0.00526841  0.00516993  0.0048638   0.00452517  0.00417899  0.00407036]\n"
     ]
    }
   ],
   "source": [
    "new_PCA=PCA(n_components=60)\n",
    "new_PCA.fit(features)\n",
    "plt.plot(new_PCA.explained_variance_ratio_)\n",
    "plt.yscale('log')\n",
    "plt.title(\"PCA explained ratio of features\")\n",
    "print new_PCA.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x23d5e748>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(new_PCA.explained_variance_ratio_.cumsum())\n",
    "plt.title(\"cumsum of PCA explained ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(labels, train_size=0.75)\n",
    "for train_index, test_index in sss:\n",
    "    features_train,features_test=features.iloc[train_index],features.iloc[test_index]\n",
    "    labels_train,labels_test=labels[train_index],labels[test_index]\n",
    "features_test.index=range(len(features_test))\n",
    "features_train.index=range(len(features_train))\n",
    "labels_train.index=range(len(labels_train))\n",
    "labels_test.index=range(len(labels_test))\n",
    "features.index=range(len(features))\n",
    "labels.index=range(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_and_fit_model(X_train,y_train,X_test=None,y_test=None,hn=32,dp=0.5,layers=1,epochs=1,batches=64,verbose=0):\n",
    "    input_dim=X_train.shape[1]\n",
    "    output_dim=len(y_train.unique())\n",
    "    Y_train=np_utils.to_categorical(y_train.cat.rename_categories(range(len(y_train.unique()))))\n",
    "    print output_dim, input_dim\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hn, input_shape=(input_dim,)))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(dp))\n",
    "\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(hn))\n",
    "        model.add(PReLU())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dp))\n",
    "\n",
    "    model.add(Dense(output_dim))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    if X_test is not None:\n",
    "        Y_test=np_utils.to_categorical(y_test.cat.rename_categories(range(len(y_test.unique()))))\n",
    "        fitting=model.fit(X_train, Y_train, nb_epoch=epochs, batch_size=batches,verbose=verbose,validation_data=(X_test,Y_test))\n",
    "        test_score = log_loss(y_test, model.predict_proba(X_test,verbose=0))\n",
    "    else:\n",
    "        model.fit(X_train, Y_train, nb_epoch=epochs, batch_size=batches,verbose=verbose)\n",
    "        fitting=0\n",
    "        test_score = 0\n",
    "    return test_score, fitting, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS=20\n",
    "N_HN=128\n",
    "N_LAYERS=1\n",
    "DP=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 70\n",
      "Train on 658486 samples, validate on 219496 samples\n",
      "Epoch 1/20\n",
      "39s - loss: 2.3799 - val_loss: 2.2118\n",
      "Epoch 2/20\n",
      "38s - loss: 2.2775 - val_loss: 2.2022\n",
      "Epoch 3/20\n",
      "42s - loss: 2.2664 - val_loss: 2.1973\n",
      "Epoch 4/20\n",
      "43s - loss: 2.2604 - val_loss: 2.1911\n",
      "Epoch 5/20\n",
      "40s - loss: 2.2554 - val_loss: 2.1907\n",
      "Epoch 6/20\n",
      "40s - loss: 2.2528 - val_loss: 2.1871\n",
      "Epoch 7/20\n",
      "41s - loss: 2.2507 - val_loss: 2.1859\n",
      "Epoch 8/20\n",
      "43s - loss: 2.2488 - val_loss: 2.1864\n",
      "Epoch 9/20\n",
      "41s - loss: 2.2478 - val_loss: 2.1825\n",
      "Epoch 10/20\n",
      "44s - loss: 2.2472 - val_loss: 2.1846\n",
      "Epoch 11/20\n",
      "43s - loss: 2.2458 - val_loss: 2.1822\n",
      "Epoch 12/20\n",
      "41s - loss: 2.2444 - val_loss: 2.1822\n",
      "Epoch 13/20\n",
      "42s - loss: 2.2439 - val_loss: 2.1824\n",
      "Epoch 14/20\n",
      "42s - loss: 2.2435 - val_loss: 2.1789\n",
      "Epoch 15/20\n",
      "42s - loss: 2.2432 - val_loss: 2.1821\n",
      "Epoch 16/20\n",
      "43s - loss: 2.2430 - val_loss: 2.1796\n",
      "Epoch 17/20\n",
      "42s - loss: 2.2426 - val_loss: 2.1783\n",
      "Epoch 18/20\n",
      "42s - loss: 2.2413 - val_loss: 2.1780\n",
      "Epoch 19/20\n",
      "43s - loss: 2.2411 - val_loss: 2.1782\n",
      "Epoch 20/20\n",
      "44s - loss: 2.2412 - val_loss: 2.1773\n"
     ]
    }
   ],
   "source": [
    "score, fitting, model = build_and_fit_model(features_train.as_matrix(),labels_train,X_test=features_test.as_matrix(),y_test=labels_test,hn=N_HN,layers=N_LAYERS,epochs=N_EPOCHS,verbose=2,dp=DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 2.17621264277\n",
      "train 2.17585184371\n",
      "test 2.17729503668\n"
     ]
    }
   ],
   "source": [
    "print \"all\", log_loss(labels, model.predict_proba(features.as_matrix(),verbose=0))\n",
    "print \"train\", log_loss(labels_train, model.predict_proba(features_train.as_matrix(),verbose=0))\n",
    "print \"test\", log_loss(labels_test, model.predict_proba(features_test.as_matrix(),verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13b2c57d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plt.plot(fitting.history['val_loss'],label=\"validation\")\n",
    "plt.plot(fitting.history['loss'],label=\"train\")\n",
    "# plt.xscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 70\n",
      "Epoch 1/20\n",
      "51s - loss: 2.3543\n",
      "Epoch 2/20\n",
      "54s - loss: 2.2705\n",
      "Epoch 3/20\n",
      "52s - loss: 2.2614\n",
      "Epoch 4/20\n",
      "51s - loss: 2.2553\n",
      "Epoch 5/20\n",
      "51s - loss: 2.2516\n",
      "Epoch 6/20\n",
      "51s - loss: 2.2502\n",
      "Epoch 7/20\n",
      "51s - loss: 2.2476\n",
      "Epoch 8/20\n",
      "51s - loss: 2.2469\n",
      "Epoch 9/20\n",
      "51s - loss: 2.2445\n",
      "Epoch 10/20\n",
      "53s - loss: 2.2436\n",
      "Epoch 11/20\n",
      "52s - loss: 2.2429\n",
      "Epoch 12/20\n",
      "52s - loss: 2.2421\n",
      "Epoch 13/20\n",
      "51s - loss: 2.2421\n",
      "Epoch 14/20\n",
      "52s - loss: 2.2409\n",
      "Epoch 15/20\n",
      "53s - loss: 2.2402\n",
      "Epoch 16/20\n",
      "52s - loss: 2.2403\n",
      "Epoch 17/20\n",
      "51s - loss: 2.2396\n",
      "Epoch 18/20\n",
      "51s - loss: 2.2392\n",
      "Epoch 19/20\n",
      "52s - loss: 2.2385\n",
      "Epoch 20/20\n",
      "51s - loss: 2.2383\n"
     ]
    }
   ],
   "source": [
    "score, fitting, model = build_and_fit_model(features.as_matrix(),labels,hn=N_HN,layers=N_LAYERS,epochs=N_EPOCHS,verbose=2,dp=DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 2.17052233917\n",
      "train 2.1714598503\n",
      "test 2.1677098143\n"
     ]
    }
   ],
   "source": [
    "print \"all\", log_loss(labels, model.predict_proba(features.as_matrix(),verbose=0))\n",
    "print \"train\", log_loss(labels_train, model.predict_proba(features_train.as_matrix(),verbose=0))\n",
    "print \"test\", log_loss(labels_test, model.predict_proba(features_test.as_matrix(),verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDF=pd.read_csv(\"../data/test.csv\")\n",
    "testDF[[\"X\",\"Y\"]]=xy_scaler.transform(testDF[[\"X\",\"Y\"]])\n",
    "#set outliers to 0\n",
    "testDF[\"X\"]=testDF[\"X\"].apply(lambda x: 0 if abs(x)>5 else x)\n",
    "testDF[\"Y\"]=testDF[\"Y\"].apply(lambda y: 0 if abs(y)>5 else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_addresses=sorted(testDF[\"Address\"].unique())\n",
    "new_A_counts=testDF.groupby(\"Address\").size()\n",
    "only_new=set(new_addresses+addresses)-set(addresses)\n",
    "only_old=set(new_addresses+addresses)-set(new_addresses)\n",
    "in_both=set(new_addresses).intersection(addresses)\n",
    "for addr in only_new:\n",
    "    PA=new_A_counts[addr]/float(len(testDF)+len(trainDF))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "    logodds[addr]=deepcopy(default_logodds)\n",
    "    logodds[addr].index=range(len(categories))\n",
    "for addr in in_both:\n",
    "    PA=(A_counts[addr]+new_A_counts[addr])/float(len(testDF)+len(trainDF))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating address features\n",
      "Parsing dates\n",
      "Creating one-hot variables\n",
      "droping processed columns\n",
      "joining one-hot features\n",
      "creating new features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:35: FutureWarning: the take_last=True keyword is deprecated, use keep='last' instead\n"
     ]
    }
   ],
   "source": [
    "features_sub, _=parse_data(testDF,logodds,logoddsPA)\n",
    "# scaler.fit(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Time', 'Day', 'Month', 'Year', 'IsInterection', 'logoddsPA', 'PD_BAYVIEW', 'PD_CENTRAL', 'PD_INGLESIDE', 'PD_MISSION', 'PD_NORTHERN', 'PD_PARK', 'PD_RICHMOND', 'PD_SOUTHERN', 'PD_TARAVAL', 'PD_TENDERLOIN', 'DAY_Friday', 'DAY_Monday', 'DAY_Saturday', 'DAY_Sunday', 'DAY_Thursday', 'DAY_Tuesday', 'DAY_Wednesday', 'logodds0', 'logodds1', 'logodds2', 'logodds3', 'logodds4', 'logodds5', 'logodds6', 'logodds7', 'logodds8', 'logodds9', 'logodds10', 'logodds11', 'logodds12', 'logodds13', 'logodds14', 'logodds15', 'logodds16', 'logodds17', 'logodds18', 'logodds19', 'logodds20', 'logodds21', 'logodds22', 'logodds23', 'logodds24', 'logodds25', 'logodds26', 'logodds27', 'logodds28', 'logodds29', 'logodds30', 'logodds31', 'logodds32', 'logodds33', 'logodds34', 'logodds35', 'logodds36', 'logodds37', 'logodds38', 'IsDup', 'Awake', 'Summer', 'Fall', 'Winter', 'Spring']\n"
     ]
    }
   ],
   "source": [
    "collist=features_sub.columns.tolist()\n",
    "print collist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARSON</th>\n",
       "      <th>ASSAULT</th>\n",
       "      <th>BAD CHECKS</th>\n",
       "      <th>BRIBERY</th>\n",
       "      <th>BURGLARY</th>\n",
       "      <th>DISORDERLY CONDUCT</th>\n",
       "      <th>DRIVING UNDER THE INFLUENCE</th>\n",
       "      <th>DRUG/NARCOTIC</th>\n",
       "      <th>DRUNKENNESS</th>\n",
       "      <th>EMBEZZLEMENT</th>\n",
       "      <th>...</th>\n",
       "      <th>SEX OFFENSES NON FORCIBLE</th>\n",
       "      <th>STOLEN PROPERTY</th>\n",
       "      <th>SUICIDE</th>\n",
       "      <th>SUSPICIOUS OCC</th>\n",
       "      <th>TREA</th>\n",
       "      <th>TRESPASS</th>\n",
       "      <th>VANDALISM</th>\n",
       "      <th>VEHICLE THEFT</th>\n",
       "      <th>WARRANTS</th>\n",
       "      <th>WEAPON LAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007325</td>\n",
       "      <td>0.080857</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.035258</td>\n",
       "      <td>1.674602e-07</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.122631</td>\n",
       "      <td>0.135539</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.004196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.095362</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.031019</td>\n",
       "      <td>1.405286e-08</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.052829</td>\n",
       "      <td>0.089445</td>\n",
       "      <td>0.035631</td>\n",
       "      <td>0.010354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.155895</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.017053</td>\n",
       "      <td>7.101684e-09</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.070508</td>\n",
       "      <td>0.174402</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.284944</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>0.032637</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.012184</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>3.686594e-07</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>0.044659</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.045664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.284944</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>0.032637</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.012184</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>3.686594e-07</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>0.044659</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.045664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ARSON   ASSAULT  BAD CHECKS   BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
       "0  0.007325  0.080857    0.000033  0.000029  0.048726            0.000864   \n",
       "1  0.003505  0.095362    0.000009  0.000032  0.001960            0.000576   \n",
       "2  0.002468  0.017544    0.000030  0.000002  0.155895            0.000273   \n",
       "3  0.001416  0.284944    0.000045  0.001642  0.015782            0.003688   \n",
       "4  0.001416  0.284944    0.000045  0.001642  0.015782            0.003688   \n",
       "\n",
       "   DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS  EMBEZZLEMENT  \\\n",
       "0                     0.001179       0.004372     0.000744      0.000194   \n",
       "1                     0.008536       0.011443     0.001551      0.000031   \n",
       "2                     0.001154       0.000436     0.000073      0.000256   \n",
       "3                     0.006474       0.056990     0.032637      0.000173   \n",
       "4                     0.006474       0.056990     0.032637      0.000173   \n",
       "\n",
       "      ...       SEX OFFENSES NON FORCIBLE  STOLEN PROPERTY   SUICIDE  \\\n",
       "0     ...                        0.000119         0.000345  0.000638   \n",
       "1     ...                        0.000024         0.000490  0.000035   \n",
       "2     ...                        0.000010         0.000080  0.000374   \n",
       "3     ...                        0.000087         0.012184  0.000550   \n",
       "4     ...                        0.000087         0.012184  0.000550   \n",
       "\n",
       "   SUSPICIOUS OCC          TREA  TRESPASS  VANDALISM  VEHICLE THEFT  WARRANTS  \\\n",
       "0        0.035258  1.674602e-07  0.003791   0.122631       0.135539  0.015837   \n",
       "1        0.031019  1.405286e-08  0.000590   0.052829       0.089445  0.035631   \n",
       "2        0.017053  7.101684e-09  0.001116   0.070508       0.174402  0.002023   \n",
       "3        0.037635  3.686594e-07  0.006069   0.044659       0.007146  0.068627   \n",
       "4        0.037635  3.686594e-07  0.006069   0.044659       0.007146  0.068627   \n",
       "\n",
       "   WEAPON LAWS  \n",
       "0     0.004196  \n",
       "1     0.010354  \n",
       "2     0.000632  \n",
       "3     0.045664  \n",
       "4     0.045664  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_sub[collist]=scaler.transform(features_sub[collist])\n",
    "\n",
    "predDF=pd.DataFrame(model.predict_proba(features_sub.as_matrix(),verbose=0),columns=sorted(labels.unique()))\n",
    "predDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predDF.to_csv(\"Crime_SF_NN_Logodds.csv\",index_label=\"Id\",na_rep=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############xgboost implementation#############\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    OTHER OFFENSES\n",
      "2    OTHER OFFENSES\n",
      "3     LARCENY/THEFT\n",
      "4     LARCENY/THEFT\n",
      "5     LARCENY/THEFT\n",
      "6     VEHICLE THEFT\n",
      "7     VEHICLE THEFT\n",
      "8     LARCENY/THEFT\n",
      "9     LARCENY/THEFT\n",
      "Name: Category, dtype: category\n",
      "Categories (39, object): [ARSON, ASSAULT, BAD CHECKS, BRIBERY, ..., VANDALISM, VEHICLE THEFT, WARRANTS, WEAPON LAWS]\n"
     ]
    }
   ],
   "source": [
    "print labels[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### converting labels\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "list(le.classes_)\n",
    "labels_num = le.transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-1655a7e98f6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlabels_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(labels_num, train_size=0.75)\n",
    "for train_index, test_index in sss:\n",
    "    features_train,features_test=features.iloc[train_index],features.iloc[test_index]\n",
    "    labels_train,labels_test=labels_num[train_index],labels_num[test_index]\n",
    "features_test.index=range(len(features_test))\n",
    "features_train.index=range(len(features_train))\n",
    "labels_train.index=range(len(labels_train))\n",
    "labels_test.index=range(len(labels_test))\n",
    "features.index=range(len(features))\n",
    "labels_num.index=range(len(labels_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix( features_train, label=labels_train)\n",
    "xg_test = xgb.DMatrix(features_test, label=labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softprob'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 39\n",
    "param['eval_metric'] = 'mlogloss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.659853\ttest-merror:0.663083\n",
      "[1]\ttrain-merror:0.657615\ttest-merror:0.660554\n"
     ]
    }
   ],
   "source": [
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 5\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "# get prediction\n",
    "pred = bst.predict( xg_test );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
